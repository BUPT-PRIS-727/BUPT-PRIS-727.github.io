<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mengqiu Xu | BUPT-PRIS-727</title>
    <link>https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/</link>
      <atom:link href="https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/index.xml" rel="self" type="application/rss+xml" />
    <description>Mengqiu Xu</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 19 Jun 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/avatar_hu9117f083d5ddf6624984381484d6835c_35087_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Mengqiu Xu</title>
      <link>https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/</link>
    </image>
    
    <item>
      <title>M4Fog: A Global Multi-Regional, Multi-Modal, and Multi-Stage Dataset for Marine Fog Detection and Forecasting to Bridge Ocean and Atmosphere</title>
      <link>https://BUPT-PRIS-727.github.io/publication/m4fog/</link>
      <pubDate>Wed, 19 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/m4fog/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Marine fog poses a significant hazard to global shipping, necessitating effective detection and forecasting to reduce economic losses. In recent years, several machine learning (ML) methods have demonstrated superior detection accuracy compared to traditional meteorological methods. However, most of these works are developed on proprietary datasets, and the few publicly accessible datasets are often limited to simplistic toy scenarios for research purposes. To advance the field, we have collected nearly a decade’s worth of multi-modal data related to continuous marine fog stages from four series of geostationary meteorological satellites, along with meteorological observations and numerical analysis, covering 15 marine regions globally where maritime fog frequently occurs. Through pixel-level manual annotation by meteorological experts, we present the most comprehensive marine fog detection and forecasting dataset to date, named M4Fog, to bridge ocean and atmosphere. The dataset comprises 68,000 “super data cubes” along four dimensions: elements, latitude, longitude and time, with a temporal resolution of half an hour and a spatial resolution of 1 kilometer. Considering practical applications, we have defined and explored three meaningful tracks with multi-metric evaluation systems: static or dynamic marine fog detection, and spatio-temporal forecasting for cloud images. Extensive benchmarking and experiments demonstrate the rationality and effectiveness of the construction concept for proposed M4Fog. The data and codes are available to whole researchers through cloud platforms to develop ML-driven marine fog solutions and mitigate adverse impacts on human activities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MoANet: A Motion Attention Network for Sea Fog Detection in Time Series Meteorological Satellite Imagery</title>
      <link>https://BUPT-PRIS-727.github.io/publication/moanet-a-motion-attention-network-for-sea-fog-detection-in-time-series-meteorological-satellite-imagery/</link>
      <pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/moanet-a-motion-attention-network-for-sea-fog-detection-in-time-series-meteorological-satellite-imagery/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection is a significant and challenging issue in meteorological satellite imagery. Distinguishing between sea fog and low clouds is challenging due to the similar morphology and brightness characteristics of these two phenomena on the imageries. Most of the existing deep learning methods are based on a single imagery feature extraction without the time-related features in imagery sequence. Although the designed temporal models, such as temporal U-Net, expand the available features from a single imagery to the consecutive frames and introduce general temporal information, the learned motion features are not explicit and can only be implicitly learned through a large amount of data. Thus, we introduce motion features obtained from continuous temporal imagery sequences into the sea fog detection task due to the discrepancy between sea fog and other types of clouds. In this article, under the motion features acquired by Horn–Schunck (HS) optical flow method and attention mechanisms, a Motion Attention Network (MoANet) for sea fog detection is proposed, named MoANet. We performed detailed experiments on the Himawaria-8 satellite imagery data set (H-8 Dataset). The Mean Intersection over Union (MIoU) of our method reaches 81.38%, which is 6.49% higher than the single imagery method. The visualization of the results shows that MoANet has more smooth edges, as well as detects more complete area than others. Furthermore, we validate on International Comprehensive Ocean-Atmosphere Data Set (ICOADS) through contrasting visibility value to prove the practicality of the proposed method and the accuracy achieves 90.65%.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Weakly Supervised Sea Fog Detection in Remote Sensing Images via Prototype Learning</title>
      <link>https://BUPT-PRIS-727.github.io/publication/weakly-supervised-sea-fog-detection-in-remote-sensing-images-via-prototype-learning/</link>
      <pubDate>Wed, 11 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/weakly-supervised-sea-fog-detection-in-remote-sensing-images-via-prototype-learning/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection is a challenging and significant task in the field of remote sensing. Deep learning-based methods have shown promising potential, but require a large amount of pixel-level labeled data that are time-consuming and labor-intensive to acquire. To scale up the dataset and overcome the limitations of pixel-level annotation, we attempt to explore the existing knowledge from historical statistics for label-efficient sea fog detection. In this article, we propose an image-level weakly supervised sea fog detection dataset (WS-SFDD) and a novel weakly supervised sea fog detection framework via prototype learning, named ProCAM. According to the sea fog events recorded by the Marine Weather Review published quarterly by the National Meteorological Center of China, we collect the sea fog images from Himawari-8 satellite data and obtain free image-level labels to construct the dataset. However, with image-level annotations, the existing weakly supervised semantic segmentation (WSSS) methods mainly rely on class activation maps (CAMs) and have limitations when applied to such a specific scenario: 1) the pseudo-labels (PLs) mainly cover the most discriminative part of object regions that are incomplete; 2) the background is complex with varying atmospheric conditions, and it is difficult to distinguish sea fog from low clouds due to their high similarity in spectral characteristics; and 3) the co-occurring context, such as “sea,” distracts the model and thus degrades the performance. To address the above issues, in our proposed ProCAM, we first design a prototype reactivation (PRA) module that reactivates self-similar sea fog regions by pixel-to-prototype feature matching to improve the robustness and completeness of CAMs. Then, we develop a pixel-to-prototype contrastive (PPC) learning method to increase the distance between sea fog and background in the embedding space for learning more discriminative dense features. Finally, a self-augmented regularization (SAR) strategy is presented to decouple sea fog from its co-ocurring context, and thus avoid background interference. Extensive experiments on the WS-SFDD dataset demonstrate that our proposed method ProCAM achieves superior performance with an $F1$ score of 77.59% and a critical success index (CSI) of 63.39%. To the best of our knowledge, this is the first work to perform image-level weakly supervised sea fog detection in remote sensing images. The dataset and code are available at &lt;a href=&#34;https://github.com/yixianghuang/ProCAM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/yixianghuang/ProCAM&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SeaMAE: Masked Pre-Training with Meteorological Satellite Imagery for Sea Fog Detection</title>
      <link>https://BUPT-PRIS-727.github.io/publication/seamae/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/seamae/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection (SFD) presents a significant challenge in the field of intelligent Earth observation, particularly in analyzing meteorological satellite imagery. Akin to various vision tasks, ImageNet pre-training is commonly used for pre-training SFD. However, in the context of multi-spectral meteorological satellite imagery, the initial step of deep learning has received limited attention. Recently, pre-training with Very High-Resolution (VHR) satellite imagery has gained increased popularity in remote-sensing vision tasks, showing the potential to replace ImageNet pre-training. However, it is worth noting that the meteorological satellite imagery applied in SFD, despite being an application of computer vision in remote sensing, differs greatly from VHR satellite imagery. To address the limitation of pre-training for SFD, this paper introduces a novel deep-learning paradigm to the meteorological domain driven by Masked Image Modeling (MIM). Our research reveals two key insights: (1) Pre-training with meteorological satellite imagery yields superior SFD performance compared to pre-training with nature imagery and VHR satellite imagery. (2) Incorporating the architectural characteristics of SFD models into a vanilla masked autoencoder (MAE) can augment the effectiveness of meteorological pre-training. To facilitate this research, we curate a pre-training dataset comprising 514,655 temporal multi-spectral meteorological satellite images, covering the Bohai Sea and Yellow Sea regions, which have the most sea fog occurrence. The longitude ranges from 115.00E to 128.75E, and the latitude ranges from 27.60N to 41.35N. Moreover, we introduce SeaMAE, a novel MAE that utilizes a Vision Transformer as the encoder and a convolutional hierarchical decoder, to learn meteorological representations. SeaMAE is pre-trained on this dataset and fine-tuned for SFD, resulting in state-of-the-art performance. For instance, using the ViT-Base as the backbone, SeaMAE pre-training which achieves 64.18% surpasses from-scratch learning, natural imagery pre-training, and VRH satellite imagery pre-training by 5.53% , 2.49% , and 2.21% , respectively, in terms of Intersection over Union of SFD.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Attention based Long Short-Term Memory Network for Coastal Visibility Forecast</title>
      <link>https://BUPT-PRIS-727.github.io/publication/attention-based-long-short-term-memory-network-for-coastal-visibility-forecast/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/attention-based-long-short-term-memory-network-for-coastal-visibility-forecast/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Visibility prediction in coastal areas has always been an important issue affecting the safety of residents and the efficiency of urban transportation. The visibility prediction methods currently used by meteorological centers are mainly based on the statistical forecast with relatively low prediction accuracy and high computational complexity. These methods cannot work well with large amounts of data. However, with the rapid development of deep learning technology, the use of deep learning has become a primary trend. In this paper, we propose our visibility prediction model based on (Long Short-Term Memory) LSTM network and self-attention mechanism. The model takes Medium-range Forecasts Data from European Centre for Mediumrange Weather Forecasting (ECMWF) which we use EC data to refer it for simplicity and observatory visibility data as input to predict and uses the LSTM network as the backbone to extract time series information. We also use self-attention mechanism to process the input data before the data is input to the model to let the model better focus on the valuable information for prediction. Compared with the predicted visibility in EC data, our proposed method improved the 3-hour prediction accuracy by 20%, 1.5 times, and 8 times for high-range, medium-range, and low-range visibility, respectively. We also find the data imbalance will greatly affect the prediction accuracy for low-visibility data and use the weighted-loss and mix-up data augmentation strategy model in our model training. We improved the accuracy of low-visibility data by 1.2 times while the prediction results of high-visibility and medium-visibility data remained almost the same. In addition, we conduct several experiments to verify the effectiveness of our model design and the rationality of data augmentation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Annotating Only at Definite Pixels- A Novel Weakly Supervised Semantic Segmentation Method for Sea Fog Recognition</title>
      <link>https://BUPT-PRIS-727.github.io/publication/annotating-only-at-definite-pixels-a-novel-weakly-supervised-semantic-segmentation-method-for-sea-fog-recognition/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/annotating-only-at-definite-pixels-a-novel-weakly-supervised-semantic-segmentation-method-for-sea-fog-recognition/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog recognition is a challenging and significant semantic segmentation task in remote sensing images. The fully supervised learning method relies on the pixel-level label, which is labor-intensive and time-consuming. Moreover, it is impossible to accurately annotate all pixels of the sea fog region due to the limited ability of the human eye to distinguish between low clouds and sea fog. In this paper, we propose a novel approach of point-based annotation for weakly supervised semantic segmentation with the auxiliary information of International Comprehensive Ocean-Atmosphere Data Set (ICOADS) visibility data. It only needs several definite points for both foreground and background, which significantly reduces the annotation cost of manpower. We conduct extensive experiments on Himawari-8 satellite remote sensing images to demonstrate the effectiveness of our annotation method. The mean intersection over union (mIoU) and overall recognition accuracy of our annotation method reach 82.72% and 95.18 %, respectively. Compared with the fully supervised learning method, the accuracy and the recognition rate of sea fog area are improved with a maximum increase of 7.69% and 9.69 %, respectively.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Identify, Guess and Reconstruct- Three Principles for Cloud Removal Task</title>
      <link>https://BUPT-PRIS-727.github.io/publication/identify-guess-and-reconstruct-three-principles-for-cloud-removal-task/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/identify-guess-and-reconstruct-three-principles-for-cloud-removal-task/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Remote sensing images serve a significant role in earth observation to tackle climate change and post-disaster reconstruction concerns. However, optical images are obscured by clouds or haze, preventing precise earth observation; hence, cloud removal has been a hot topic among concerned scholars. The objective of this article is to make cloud removal more efficient and explicable by proposing three principles: identifying clouds, guessing objects beneath the clouds, and reconstructing the cloudy area. In addition, a modified dual contrastive learning Generative Adversarial Network is proposed based on these three principles by adding cloud detection and weight sharing strategy to obtain cloud semantics. In particular, we align two datasets by forming a quaternary sample pair that includes not only optical pictures and SAR images, but also region information for a more precise reconstruction. Our experiment results on the integrated dataset reveal the superiority of proposed method over previous cloud removal methods and the effectiveness of added modules through ablation experiments, with PSNR and SSIM values of 26.2 and 0.728, respectively.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Eyes of the Gods: A Survey of Unsupervised Domain Adaptation Methods Based on Remote Sensing Data</title>
      <link>https://BUPT-PRIS-727.github.io/publication/the-eyes-of-the-gods/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/the-eyes-of-the-gods/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;With the rapid development of the remote sensing monitoring and computer vision technology, the deep learning method has made a great progress to achieve applications such as earth observation, climate change and even space exploration. However, the model trained on existing data cannot be directly used to handle the new remote sensing data, and labeling the new data is also time-consuming and labor-intensive. Unsupervised Domain Adaptation (UDA) is one of the solutions to the aforementioned problems of labeled data defined as the source domain and unlabeled data as the target domain, i.e., its essential purpose is to obtain a well-trained model and tackle the problem of data distribution discrepancy defined as the domain shift between the source and target domain. There are a lot of reviews that have elaborated on UDA methods based on natural data, but few of these studies take into consideration thorough remote sensing applications and contributions. Thus, in this paper, in order to explore the further progress and development of UDA methods in remote sensing, based on the analysis of the causes of domain shift, a comprehensive review is provided with a fine-grained taxonomy of UDA methods applied for remote sensing data, which includes Generative training, Adversarial training, Self-training and Hybrid training methods, to better assist scholars in understanding remote sensing data and further advance the development of methods. Moreover, remote sensing applications are introduced by a thorough dataset analysis. Meanwhile, we sort out definitions and methodology introductions of partial, open-set and multi-domain UDA, which are more pertinent to real-world remote sensing applications. We can draw the conclusion that UDA methods in the field of remote sensing data are carried out later than those applied in natural images, and due to the domain gap caused by appearance differences, most of methods focus on how to use generative training (GT) methods to improve the model’s performance. Finally, we describe the potential deficiencies and further in-depth insights of UDA in the field of remote sensing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Domain Adaptation on Multiple Cloud Recognition From Different Types of Meteorological Satellite</title>
      <link>https://BUPT-PRIS-727.github.io/publication/domain-adaptation-on-multiple-cloud-recognition-from-different-types-of-meteorological-satellite/</link>
      <pubDate>Fri, 12 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/domain-adaptation-on-multiple-cloud-recognition-from-different-types-of-meteorological-satellite/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Meteorological satellites have become an indispensable meteorological tool for earth observation, as aiding in areas such as cloud detection, which has important guiding significance for maritime activities. However, it is time-consuming and labor-intensive to obtain fine-grained annotations provided by artificial experience or mature satellite cloud products for multi-spectral maritime cloud imageries, especially when new satellites are launched. Moreover, due to the data discrepancy caused by different detection bands, existing models have inadequate generalization performance compared to new satellites, and some cannot be directly migrated. In this paper, to reduce the data distribution’s discrepancy, an approach is presented based on unsupervised domain adaption method for marine cloud detection task based on Himawari-8 satellite data as a source domain and Fengyun-4 satellite data as a target domain. The goal of the proposed method is to leverage the representation power of adversarial learning to extract domain-invariant features, consisting of a segmentation model, a feature extract model for target domain, and a domain discriminator. In addition, aiming to remedy the discrepancy of detection bands, a band mapping module is designed to implement consistency between different bands. The result of the experiments demonstrated the effectiveness of the proposed method with a 7% improvement compared with the comparative experiment. We also designed a series of statistical experiments on different satellite data to further study cloudy perception representation, including data visualization experiment and cloud type statistics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sea fog detection based on unsupervised domain adaptation</title>
      <link>https://BUPT-PRIS-727.github.io/publication/sea-fog-detection-based-on-unsupervised-domain-adaptation/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/sea-fog-detection-based-on-unsupervised-domain-adaptation/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection with remote sensing images is a challenging task. Driven by the different image characteristics between fog and other types of clouds, such as textures and colors, it can be achieved by using image processing methods. Currently, most of the available methods are data-driven and relying on manual annotations. However, because few meteorological observations and buoys over the sea can be realized, obtaining visibility information to help the annotations is difficult. Considering the feasibility of obtaining abundant visible information over the land and the similarity between land fog and sea fog, we propose an unsupervised domain adaptation method to bridge the abundant labeled land fog data and the unlabeled sea fog data to realize the sea fog detection. We used a seeded region growing module to obtain pixel-level masks from rough-labels generated by the unsupervised domain adaptation model. Experimental results demonstrate that our proposed method achieves an accuracy of sea fog recognition up to 99.17%, which is nearly 3% higher than those vanilla methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>基于无监督域适应的不同类型气象卫星的多云识别系统</title>
      <link>https://BUPT-PRIS-727.github.io/project/%E5%9F%BA%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9F%9F%E9%80%82%E5%BA%94%E7%9A%84%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E7%9A%84%E5%A4%9A%E4%BA%91%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/project/%E5%9F%BA%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9F%9F%E9%80%82%E5%BA%94%E7%9A%84%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E7%9A%84%E5%A4%9A%E4%BA%91%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Correlation Context-Driven Method for Sea Fog Detection in Meteorological Satellite Imagery</title>
      <link>https://BUPT-PRIS-727.github.io/publication/a-correlation-context-driven-method-for-sea-fog-detection-in-meteorological-satellite-imagery/</link>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publication/a-correlation-context-driven-method-for-sea-fog-detection-in-meteorological-satellite-imagery/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection is a challenging and essential issue in satellite remote sensing. Although conventional threshold methods and deep learning methods can achieve pixel-level classification, it is difficult to distinguish ambiguous boundaries and thin structures from the background. Considering the correlations between neighbor pixels and the affinities between superpixels, a correlation context-driven method for sea fog detection is proposed in this letter, which mainly consists of a two-stage superpixel-based fully convolutional network (SFCNet), named SFCNet. A fully connected Conditional Random Field (CRF) is utilized to model the dependencies between pixels. To alleviate the problem of high cloud occlusion, an attentive Generative Adversarial Network (GAN) is implemented for image enhancement by exploiting contextual information. Experimental results demonstrate that our proposed method achieves 91.65% mIoU and obtains more refined segmentation results, performing well in detecting fogs in small, broken bits and weak contrast thin structures, as well as detects more obscured parts.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
