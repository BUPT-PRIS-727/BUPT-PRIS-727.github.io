<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mengqiu Xu | BUPT-PRIS-727</title>
    <link>https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/</link>
      <atom:link href="https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/index.xml" rel="self" type="application/rss+xml" />
    <description>Mengqiu Xu</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 19 Jun 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/avatar_hu9117f083d5ddf6624984381484d6835c_35087_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Mengqiu Xu</title>
      <link>https://BUPT-PRIS-727.github.io/authors/mengqiu-xu/</link>
    </image>
    
    <item>
      <title>M4Fog: A Global Multi-Regional, Multi-Modal, and Multi-Stage Dataset for Marine Fog Detection and Forecasting to Bridge Ocean and Atmosphere</title>
      <link>https://BUPT-PRIS-727.github.io/publications/m4fog/</link>
      <pubDate>Wed, 19 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publications/m4fog/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Marine fog poses a significant hazard to global shipping, necessitating effective detection and forecasting to reduce economic losses. In recent years, several machine learning (ML) methods have demonstrated superior detection accuracy compared to traditional meteorological methods. However, most of these works are developed on proprietary datasets, and the few publicly accessible datasets are often limited to simplistic toy scenarios for research purposes. To advance the field, we have collected nearly a decade’s worth of multi-modal data related to continuous marine fog stages from four series of geostationary meteorological satellites, along with meteorological observations and numerical analysis, covering 15 marine regions globally where maritime fog frequently occurs. Through pixel-level manual annotation by meteorological experts, we present the most comprehensive marine fog detection and forecasting dataset to date, named M4Fog, to bridge ocean and atmosphere. The dataset comprises 68,000 “super data cubes” along four dimensions: elements, latitude, longitude and time, with a temporal resolution of half an hour and a spatial resolution of 1 kilometer. Considering practical applications, we have defined and explored three meaningful tracks with multi-metric evaluation systems: static or dynamic marine fog detection, and spatio-temporal forecasting for cloud images. Extensive benchmarking and experiments demonstrate the rationality and effectiveness of the construction concept for proposed M4Fog. The data and codes are available to whole researchers through cloud platforms to develop ML-driven marine fog solutions and mitigate adverse impacts on human activities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Weakly Supervised Sea Fog Detection in Remote Sensing Images via Prototype Learning</title>
      <link>https://BUPT-PRIS-727.github.io/publications/weakly-supervised-sea-fog-detection-in-remote-sensing-images-via-prototype-learning/</link>
      <pubDate>Wed, 11 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publications/weakly-supervised-sea-fog-detection-in-remote-sensing-images-via-prototype-learning/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection is a challenging and significant task in the field of remote sensing. Deep learning-based methods have shown promising potential, but require a large amount of pixel-level labeled data that are time-consuming and labor-intensive to acquire. To scale up the dataset and overcome the limitations of pixel-level annotation, we attempt to explore the existing knowledge from historical statistics for label-efficient sea fog detection. In this article, we propose an image-level weakly supervised sea fog detection dataset (WS-SFDD) and a novel weakly supervised sea fog detection framework via prototype learning, named ProCAM. According to the sea fog events recorded by the Marine Weather Review published quarterly by the National Meteorological Center of China, we collect the sea fog images from Himawari-8 satellite data and obtain free image-level labels to construct the dataset. However, with image-level annotations, the existing weakly supervised semantic segmentation (WSSS) methods mainly rely on class activation maps (CAMs) and have limitations when applied to such a specific scenario: 1) the pseudo-labels (PLs) mainly cover the most discriminative part of object regions that are incomplete; 2) the background is complex with varying atmospheric conditions, and it is difficult to distinguish sea fog from low clouds due to their high similarity in spectral characteristics; and 3) the co-occurring context, such as “sea,” distracts the model and thus degrades the performance. To address the above issues, in our proposed ProCAM, we first design a prototype reactivation (PRA) module that reactivates self-similar sea fog regions by pixel-to-prototype feature matching to improve the robustness and completeness of CAMs. Then, we develop a pixel-to-prototype contrastive (PPC) learning method to increase the distance between sea fog and background in the embedding space for learning more discriminative dense features. Finally, a self-augmented regularization (SAR) strategy is presented to decouple sea fog from its co-ocurring context, and thus avoid background interference. Extensive experiments on the WS-SFDD dataset demonstrate that our proposed method ProCAM achieves superior performance with an $F1$ score of 77.59% and a critical success index (CSI) of 63.39%. To the best of our knowledge, this is the first work to perform image-level weakly supervised sea fog detection in remote sensing images. The dataset and code are available at &lt;a href=&#34;https://github.com/yixianghuang/ProCAM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/yixianghuang/ProCAM&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Identify, Guess and Reconstruct- Three Principles for Cloud Removal Task</title>
      <link>https://BUPT-PRIS-727.github.io/publications/identify-guess-and-reconstruct-three-principles-for-cloud-removal-task/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publications/identify-guess-and-reconstruct-three-principles-for-cloud-removal-task/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Remote sensing images serve a significant role in earth observation to tackle climate change and post-disaster reconstruction concerns. However, optical images are obscured by clouds or haze, preventing precise earth observation; hence, cloud removal has been a hot topic among concerned scholars. The objective of this article is to make cloud removal more efficient and explicable by proposing three principles: identifying clouds, guessing objects beneath the clouds, and reconstructing the cloudy area. In addition, a modified dual contrastive learning Generative Adversarial Network is proposed based on these three principles by adding cloud detection and weight sharing strategy to obtain cloud semantics. In particular, we align two datasets by forming a quaternary sample pair that includes not only optical pictures and SAR images, but also region information for a more precise reconstruction. Our experiment results on the integrated dataset reveal the superiority of proposed method over previous cloud removal methods and the effectiveness of added modules through ablation experiments, with PSNR and SSIM values of 26.2 and 0.728, respectively.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Eyes of the Gods: A Survey of Unsupervised Domain Adaptation Methods Based on Remote Sensing Data</title>
      <link>https://BUPT-PRIS-727.github.io/publications/the-eyes-of-the-gods/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publications/the-eyes-of-the-gods/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;With the rapid development of the remote sensing monitoring and computer vision technology, the deep learning method has made a great progress to achieve applications such as earth observation, climate change and even space exploration. However, the model trained on existing data cannot be directly used to handle the new remote sensing data, and labeling the new data is also time-consuming and labor-intensive. Unsupervised Domain Adaptation (UDA) is one of the solutions to the aforementioned problems of labeled data defined as the source domain and unlabeled data as the target domain, i.e., its essential purpose is to obtain a well-trained model and tackle the problem of data distribution discrepancy defined as the domain shift between the source and target domain. There are a lot of reviews that have elaborated on UDA methods based on natural data, but few of these studies take into consideration thorough remote sensing applications and contributions. Thus, in this paper, in order to explore the further progress and development of UDA methods in remote sensing, based on the analysis of the causes of domain shift, a comprehensive review is provided with a fine-grained taxonomy of UDA methods applied for remote sensing data, which includes Generative training, Adversarial training, Self-training and Hybrid training methods, to better assist scholars in understanding remote sensing data and further advance the development of methods. Moreover, remote sensing applications are introduced by a thorough dataset analysis. Meanwhile, we sort out definitions and methodology introductions of partial, open-set and multi-domain UDA, which are more pertinent to real-world remote sensing applications. We can draw the conclusion that UDA methods in the field of remote sensing data are carried out later than those applied in natural images, and due to the domain gap caused by appearance differences, most of methods focus on how to use generative training (GT) methods to improve the model’s performance. Finally, we describe the potential deficiencies and further in-depth insights of UDA in the field of remote sensing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sea fog detection based on unsupervised domain adaptation</title>
      <link>https://BUPT-PRIS-727.github.io/publications/sea-fog-detection-based-on-unsupervised-domain-adaptation/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publications/sea-fog-detection-based-on-unsupervised-domain-adaptation/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection with remote sensing images is a challenging task. Driven by the different image characteristics between fog and other types of clouds, such as textures and colors, it can be achieved by using image processing methods. Currently, most of the available methods are data-driven and relying on manual annotations. However, because few meteorological observations and buoys over the sea can be realized, obtaining visibility information to help the annotations is difficult. Considering the feasibility of obtaining abundant visible information over the land and the similarity between land fog and sea fog, we propose an unsupervised domain adaptation method to bridge the abundant labeled land fog data and the unlabeled sea fog data to realize the sea fog detection. We used a seeded region growing module to obtain pixel-level masks from rough-labels generated by the unsupervised domain adaptation model. Experimental results demonstrate that our proposed method achieves an accuracy of sea fog recognition up to 99.17%, which is nearly 3% higher than those vanilla methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Correlation Context-Driven Method for Sea Fog Detection in Meteorological Satellite Imagery</title>
      <link>https://BUPT-PRIS-727.github.io/publications/a-correlation-context-driven-method-for-sea-fog-detection-in-meteorological-satellite-imagery/</link>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://BUPT-PRIS-727.github.io/publications/a-correlation-context-driven-method-for-sea-fog-detection-in-meteorological-satellite-imagery/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;Sea fog detection is a challenging and essential issue in satellite remote sensing. Although conventional threshold methods and deep learning methods can achieve pixel-level classification, it is difficult to distinguish ambiguous boundaries and thin structures from the background. Considering the correlations between neighbor pixels and the affinities between superpixels, a correlation context-driven method for sea fog detection is proposed in this letter, which mainly consists of a two-stage superpixel-based fully convolutional network (SFCNet), named SFCNet. A fully connected Conditional Random Field (CRF) is utilized to model the dependencies between pixels. To alleviate the problem of high cloud occlusion, an attentive Generative Adversarial Network (GAN) is implemented for image enhancement by exploiting contextual information. Experimental results demonstrate that our proposed method achieves 91.65% mIoU and obtains more refined segmentation results, performing well in detecting fogs in small, broken bits and weak contrast thin structures, as well as detects more obscured parts.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
