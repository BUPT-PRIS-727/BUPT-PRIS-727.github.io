
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1718755200,"objectID":"890de7da2d85d86bcb2cc68256a0375e","permalink":"https://BUPT-PRIS-727.github.io/en/authors/chuang-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/chuang-zhang/","section":"authors","summary":"","tags":null,"title":"Chuang Zhang","type":"authors"},{"authors":null,"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1718755200,"objectID":"e829e7859b84bc39e6561775d1cd5f02","permalink":"https://BUPT-PRIS-727.github.io/en/authors/kaixin-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/kaixin-chen/","section":"authors","summary":"","tags":null,"title":"Kaixin Chen","type":"authors"},{"authors":null,"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1718755200,"objectID":"e4888d1c039497bf12ea5cdc8d23c019","permalink":"https://BUPT-PRIS-727.github.io/en/authors/mengqiu-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/mengqiu-xu/","section":"authors","summary":"","tags":null,"title":"Mengqiu Xu","type":"authors"},{"authors":null,"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1718755200,"objectID":"9b9363c6226705e57e6840dbc5879ee6","permalink":"https://BUPT-PRIS-727.github.io/en/authors/ming-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/ming-wu/","section":"authors","summary":"","tags":null,"title":"Ming Wu","type":"authors"},{"authors":null,"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1718755200,"objectID":"e3c740f33c31779c02884904ea4a80b2","permalink":"https://BUPT-PRIS-727.github.io/en/authors/mingrui-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/mingrui-xu/","section":"authors","summary":"","tags":null,"title":"Mingrui Xu","type":"authors"},{"authors":null,"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1718755200,"objectID":"f7c0ab6ead3874254f222a0ab35e46e2","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yiqing-feng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yiqing-feng/","section":"authors","summary":"","tags":null,"title":"Yiqing Feng","type":"authors"},{"authors":null,"categories":null,"content":"","date":1718755200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1718755200,"objectID":"5b8bc4d49b4e279fd3253e37a988ab3a","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yixiang-huang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yixiang-huang/","section":"authors","summary":"","tags":null,"title":"Yixiang Huang","type":"authors"},{"authors":null,"categories":null,"content":"","date":1701993600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1701993600,"objectID":"5b2b86a9bd1d345bd36b999303ff7481","permalink":"https://BUPT-PRIS-727.github.io/en/authors/xun-zhu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/xun-zhu/","section":"authors","summary":"","tags":null,"title":"Xun Zhu","type":"authors"},{"authors":null,"categories":null,"content":"","date":1701993600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1701993600,"objectID":"c8e079184dbdf82baf7a02a00862d213","permalink":"https://BUPT-PRIS-727.github.io/en/authors/ziheng-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/ziheng-yang/","section":"authors","summary":"","tags":null,"title":"Ziheng Yang","type":"authors"},{"authors":null,"categories":null,"content":"","date":1696982400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1696982400,"objectID":"822c192028c5791581437b171a09e7da","permalink":"https://BUPT-PRIS-727.github.io/en/authors/jiaao-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/jiaao-li/","section":"authors","summary":"","tags":null,"title":"Jiaao Li","type":"authors"},{"authors":null,"categories":null,"content":"","date":1692576000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1692576000,"objectID":"a048f8fa5474c33127e84a88518eb118","permalink":"https://BUPT-PRIS-727.github.io/en/authors/haotian-yan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/haotian-yan/","section":"authors","summary":"","tags":null,"title":"Haotian Yan","type":"authors"},{"authors":null,"categories":null,"content":"","date":1692576000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1692576000,"objectID":"8f93af1726893dfc24b779b6008146ad","permalink":"https://BUPT-PRIS-727.github.io/en/authors/sundingkai-su/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/sundingkai-su/","section":"authors","summary":"","tags":null,"title":"Sundingkai Su","type":"authors"},{"authors":null,"categories":null,"content":"","date":1692576000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1692576000,"objectID":"db93c2f08660b61d9d6d4a7518c91af2","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yihao-zuo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yihao-zuo/","section":"authors","summary":"","tags":null,"title":"Yihao Zuo","type":"authors"},{"authors":null,"categories":null,"content":"","date":1676937600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676937600,"objectID":"2367703eb4402cd22454b6f09de4a7a6","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yutong-xiong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yutong-xiong/","section":"authors","summary":"","tags":null,"title":"Yutong Xiong","type":"authors"},{"authors":null,"categories":null,"content":"","date":1660262400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1660262400,"objectID":"6db3d5bf80812f3997dee11992c2aefd","permalink":"https://BUPT-PRIS-727.github.io/en/authors/luming-xiao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/luming-xiao/","section":"authors","summary":"","tags":null,"title":"Luming Xiao","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640908800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640908800,"objectID":"ae1bdb472c7765b6466627a1cfe21380","permalink":"https://BUPT-PRIS-727.github.io/en/authors/cheng-lv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/cheng-lv/","section":"authors","summary":"","tags":null,"title":"Cheng Lv","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6885266821bef1c93b44064c7736093c","permalink":"https://BUPT-PRIS-727.github.io/en/authors/bingyao-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/bingyao-li/","section":"authors","summary":"","tags":null,"title":"Bingyao Li","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8730eb05528d4ee5f369d116b9c0e141","permalink":"https://BUPT-PRIS-727.github.io/en/authors/bo-yao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/bo-yao/","section":"authors","summary":"","tags":null,"title":"Bo Yao","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"771202abaf93890a876fbdc75c609e74","permalink":"https://BUPT-PRIS-727.github.io/en/authors/boyuan-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/boyuan-jin/","section":"authors","summary":"","tags":null,"title":"Boyuan Jin","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"aafcd2b0225dc19448fd194523bbfcf5","permalink":"https://BUPT-PRIS-727.github.io/en/authors/di-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/di-wu/","section":"authors","summary":"","tags":null,"title":"Di Wu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a14d62fcd5a43abed42108c71ef81a01","permalink":"https://BUPT-PRIS-727.github.io/en/authors/fanbin-mo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/fanbin-mo/","section":"authors","summary":"","tags":null,"title":"Fanbin Mo","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bde8f9a7e97c320b1ceed4fdecd357fb","permalink":"https://BUPT-PRIS-727.github.io/en/authors/hailong-guo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/hailong-guo/","section":"authors","summary":"","tags":null,"title":"Hailong Guo","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e751cde208696d763825a05ee80d3f0d","permalink":"https://BUPT-PRIS-727.github.io/en/authors/haizhao-sun/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/haizhao-sun/","section":"authors","summary":"","tags":null,"title":"Haizhao Sun","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bbe1d7879136b10f4cbf22843ae91a2e","permalink":"https://BUPT-PRIS-727.github.io/en/authors/huiying-chang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/huiying-chang/","section":"authors","summary":"","tags":null,"title":"Huiying Chang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1ce4ea1eb27e3bf4a2175ad20a588eed","permalink":"https://BUPT-PRIS-727.github.io/en/authors/jiahui-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/jiahui-xu/","section":"authors","summary":"","tags":null,"title":"Jiahui Xu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f0443faf198b929a51494cdab2f62e11","permalink":"https://BUPT-PRIS-727.github.io/en/authors/jiaxin-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/jiaxin-chen/","section":"authors","summary":"","tags":null,"title":"Jiaxin Chen","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e45b7b57a09c76fa0998f8d7cf3e6931","permalink":"https://BUPT-PRIS-727.github.io/en/authors/lixuan-du/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/lixuan-du/","section":"authors","summary":"","tags":null,"title":"Lixuan Du","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0cf00645c7d590cd41f4c193fcf5cc32","permalink":"https://BUPT-PRIS-727.github.io/en/authors/ran-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/ran-xu/","section":"authors","summary":"","tags":null,"title":"Ran Xu","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"42e4dfb126451ef336f3131f38d72461","permalink":"https://BUPT-PRIS-727.github.io/en/authors/ruhao-xia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/ruhao-xia/","section":"authors","summary":"","tags":null,"title":"Ruhao Xia","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"81e756cc2bd7e1d8d74e06bf0c735c68","permalink":"https://BUPT-PRIS-727.github.io/en/authors/ruizhe-ou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/ruizhe-ou/","section":"authors","summary":"","tags":null,"title":"Ruizhe Ou","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c465fc7fbd6e8af7583ccea1d2d635bd","permalink":"https://BUPT-PRIS-727.github.io/en/authors/shenwei-xie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/shenwei-xie/","section":"authors","summary":"","tags":null,"title":"Shenwei Xie","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9e4f37eae80b7036984e1a84ba294600","permalink":"https://BUPT-PRIS-727.github.io/en/authors/sian-xie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/sian-xie/","section":"authors","summary":"","tags":null,"title":"Sian Xie","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b546cc486f4b42e827779656e5949792","permalink":"https://BUPT-PRIS-727.github.io/en/authors/weiqing-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/weiqing-li/","section":"authors","summary":"","tags":null,"title":"Weiqing Li","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da21e522c31f96dfb9db7a331d1336c2","permalink":"https://BUPT-PRIS-727.github.io/en/authors/xiao-deng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/xiao-deng/","section":"authors","summary":"","tags":null,"title":"Xiao Deng","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"07a2e017d3b6c9e8c3d055af5b9f6942","permalink":"https://BUPT-PRIS-727.github.io/en/authors/xing-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/xing-zhang/","section":"authors","summary":"","tags":null,"title":"Xing Zhang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9da025946c38b8355b89e32189da3bba","permalink":"https://BUPT-PRIS-727.github.io/en/authors/xu-ji/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/xu-ji/","section":"authors","summary":"","tags":null,"title":"Xu Ji","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da80017351a9ee250ffdfd4a5864c2dd","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yi-zhong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yi-zhong/","section":"authors","summary":"","tags":null,"title":"Yi Zhong","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6ee337ccf45dc076a377ec672d885371","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yifeng-tao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yifeng-tao/","section":"authors","summary":"","tags":null,"title":"Yifeng Tao","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c64277cd1b920414381b98a16d439fb2","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yu-gong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yu-gong/","section":"authors","summary":"","tags":null,"title":"Yu Gong","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f894fcea9c2db0ad9fe367a7664a6ba8","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yu-ning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yu-ning/","section":"authors","summary":"","tags":null,"title":"Yu Ning","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cf6b7def49acf62aabbde32696ea7971","permalink":"https://BUPT-PRIS-727.github.io/en/authors/yucheng-song/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/yucheng-song/","section":"authors","summary":"","tags":null,"title":"Yucheng Song","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fb72b47c7934b5a47f9f70a1c2ff2b66","permalink":"https://BUPT-PRIS-727.github.io/en/authors/zhenglin-xian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/zhenglin-xian/","section":"authors","summary":"","tags":null,"title":"Zhenglin Xian","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1bf8637398b88387630981cdf87c2ae7","permalink":"https://BUPT-PRIS-727.github.io/en/authors/zhengrui-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/zhengrui-chen/","section":"authors","summary":"","tags":null,"title":"Zhengrui Chen","type":"authors"},{"authors":["Mengqiu Xu","Ming Wu","Kaixin Chen","Yixiang Huang","Mingrui Xu","Yujia Yang","Yiqing Feng","Yiying Guo","Bin Huang","Dongliang Chang","Zhenwei Shi","Chuang Zhang","Zhanyu Ma","Jun Guo"],"categories":null,"content":"M4Fog dataset Overall We have collected nearly a decade’s worth of multi-modal data related to continuous marine fog stages from four series of geostationary meteorological satellites, along with meteorological observations and numerical analysis, covering 15 marine regions globally where maritime fog frequently occurs. Through pixel-level manual annotation by meteorological experts, we present the most comprehensive marine fog detection and forecasting dataset to date, named M4Fog, to bridge ocean and atmosphere. The dataset comprises 68,000 “super data cubes” along four dimensions: elements, latitude, longitude and time, with a temporal resolution of half an hour and a spatial resolution of 1 kilometer. Considering practical applications, we have defined and explored three meaningful tracks with multi-metric evaluation systems: static or dynamic marine fog detection, and spatio-temporal forecasting for cloud images.\nFigure 1: The overall construction flowchart of the proposed super data cubes in M4Fog is as follows. A variety of meteorological data related to marine fog detection and forecasting is obtained from geostationary satellites, numerical analysis, and observation databases. The super data cube is then constructed along four dimensions: elements, latitude, longitude, and time. According to visibility (VV) and present weather (WW) from observatories, the presence and absence of marine fog are determined. Subsequently, M4Fog can support multiple meaningful tracks, including static/dynamic marine fog detection and spatio-temporal forecasting.\nM4Fog data-processing In this section, we present several types of meteorological data used in M4Fog, including stationary meteorological satellite data, numerical analysis data, and observation data. We primarily outline the data processing workflow from the RAW files to multi-dimensional Arrays.\nThe data-processing of geostationary satellites data\nIn the M4Fog dataset, most of the stationary meteorological satellite data can be obtained from the Level 1 (L1) data of their imagers, such as the FY4A/4B and GOES series. However, the Meteo satellite data is sourced from the original Level 1.5 data. After processes such as reading, projection, and format conversion, we can acquire a three-dimensional array (C, H, W). Additionally, we provide synthesis functions for generating true or natural-color images for all kinds of satellites. [Refer to ‘Data_process/Satellites/’]\nThe data-processing of numerical analysis data\nBuilding on the multi-channel stationary meteorological satellite data, we further supplemented the dataset with land-sea masks and sea surface temperature (SST) numerical analysis data. Currently, the publicly available sea surface temperature data is daily, which means that for different times on the same day, the same SST file is provided. We also performed raw data reading, processing, and format conversion on the sea temperature data, ultimately resulting in a two-dimensional array (H, W). Additionally, we offer visualization methods for the sea temperature and other related data. [Refer to ‘Data_process/Numerical/’]\nThe data-processing of observation databases data\nObservation data is primarily obtained from offshore buoys, vessels, ocean observation platforms, and coastal observation stations, recording weather phenomena and related meteorological variables such as temperature, humidity, visibility, and weather codes. The original observational data formats are typically .000/.dat or compressed files. We filter the observational records corresponding to the image data based on time and geographic coordinates to create a new text file. It is important to note that for data that do not directly record fog-related meteorological conditions, secondary assessments will be conducted using meteorological principles. [Refer to ‘Data_process/Observations/’]\nM4Fog Dataset Downloading In order to facilitate data storage and download, we have separated and stored the elements in M4Fog Dataset. Dense data such as geostationary satellite images, sea surface temperature, and constant data are stored in arrays, while sparse data, like observations from monitoring stations, are stored in text format. We have published the data links and brief descriptions in the order of Tracks A to C.\nTrack A sub-dataset\nWe have released multiple sub-datasets in Track-A, which are divided based on regions and satellites. Each data cube is a labeled three-dimensional array with dimensions (C, H, W), based on multi-channel geostationary satellite data and supplemented with other data such as sea surface temperature. Dense data and sparse data are strictly aligned with the fog events in terms of time and space.\nHimawari-8/9 data in Yellow and Bohai Sea: 1,802 data cubes (CxHxW = (16+1+1)x1024x1024), including Himawari 8/9, SST, Constant Dense Data. Baidu Netdisk (password: 6vm7) Fengyun-4A Yellow and Bohai Sea: 1,724 data cubes (CxHxW = (14+1+1)x1024x1024), including Fengyun 4A, …","date":1718755200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718755200,"objectID":"e98b2aa8c86b5575f69baad5a867fa94","permalink":"https://BUPT-PRIS-727.github.io/en/publication/m4fog/","publishdate":"2024-06-19T00:00:00Z","relpermalink":"/en/publication/m4fog/","section":"publication","summary":"This is the code and data for M4Fog: A Global Multi-Regional, Multi-Modal, and Multi-Stage Dataset for Marine Fog Detection and Forecasting to Bridge Ocean and Atmosphere (https://arxiv.org/html/2406.13317v1)","tags":["Marine Fog","Dataset"],"title":"M4Fog: A Global Multi-Regional, Multi-Modal, and Multi-Stage Dataset for Marine Fog Detection and Forecasting to Bridge Ocean and Atmosphere","type":"publication"},{"authors":["Ziheng Yang","Ming Wu","Mengqiu Xu","Xun Zhu","Chuang Zhang","Bin Zhang"],"categories":null,"content":"","date":1701993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701993600,"objectID":"4bc49c3a4c7a380347c2ef116fa8fdae","permalink":"https://BUPT-PRIS-727.github.io/en/publication/moanet-a-motion-attention-network-for-sea-fog-detection-in-time-series-meteorological-satellite-imagery/","publishdate":"2023-12-08T00:00:00Z","relpermalink":"/en/publication/moanet-a-motion-attention-network-for-sea-fog-detection-in-time-series-meteorological-satellite-imagery/","section":"publication","summary":"Sea fog detection is a significant and challenging issue in meteorological satellite imagery. Distinguishing between sea fog and low clouds is challenging due to the similar morphology and brightness characteristics of these two phenomena on the imageries. Most of the existing deep learning methods are based on a single imagery feature extraction without the time-related features in imagery sequence. Although the designed temporal models, such as temporal U-Net, expand the available features from a single imagery to the consecutive frames and introduce general temporal information, the learned motion features are not explicit and can only be implicitly learned through a large amount of data. Thus, we introduce motion features obtained from continuous temporal imagery sequences into the sea fog detection task due to the discrepancy between sea fog and other types of clouds. In this article, under the motion features acquired by Horn–Schunck (HS) optical flow method and attention mechanisms, a Motion Attention Network (MoANet) for sea fog detection is proposed, named MoANet. We performed detailed experiments on the Himawaria-8 satellite imagery data set (H-8 Dataset). The Mean Intersection over Union (MIoU) of our method reaches 81.38%, which is 6.49% higher than the single imagery method. The visualization of the results shows that MoANet has more smooth edges, as well as detects more complete area than others. Furthermore, we validate on International Comprehensive Ocean-Atmosphere Data Set (ICOADS) through contrasting visibility value to prove the practicality of the proposed method and the accuracy achieves 90.65%.","tags":["Attention map","image segmentation","motion features","optical flow","sea fog detection"],"title":"MoANet: A Motion Attention Network for Sea Fog Detection in Time Series Meteorological Satellite Imagery","type":"publication"},{"authors":["Yixiang Huang","Ming Wu","Xin Jiang","Jiaao Li","Mengqiu Xu","Chuang Zhang","Jun Guo"],"categories":null,"content":"","date":1696982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696982400,"objectID":"5ec15d201cfece043ed9cc33931e2d97","permalink":"https://BUPT-PRIS-727.github.io/en/publication/weakly-supervised-sea-fog-detection-in-remote-sensing-images-via-prototype-learning/","publishdate":"2023-10-11T00:00:00Z","relpermalink":"/en/publication/weakly-supervised-sea-fog-detection-in-remote-sensing-images-via-prototype-learning/","section":"publication","summary":"Sea fog detection is a challenging and significant task in the field of remote sensing. Deep learning-based methods have shown promising potential, but require a large amount of pixel-level labeled data that are time-consuming and labor-intensive to acquire. To scale up the dataset and overcome the limitations of pixel-level annotation, we attempt to explore the existing knowledge from historical statistics for label-efficient sea fog detection. In this article, we propose an image-level weakly supervised sea fog detection dataset (WS-SFDD) and a novel weakly supervised sea fog detection framework via prototype learning, named ProCAM. According to the sea fog events recorded by the Marine Weather Review published quarterly by the National Meteorological Center of China, we collect the sea fog images from Himawari-8 satellite data and obtain free image-level labels to construct the dataset. However, with image-level annotations, the existing weakly supervised semantic segmentation (WSSS) methods mainly rely on class activation maps (CAMs) and have limitations when applied to such a specific scenario: 1) the pseudo-labels (PLs) mainly cover the most discriminative part of object regions that are incomplete; 2) the background is complex with varying atmospheric conditions, and it is difficult to distinguish sea fog from low clouds due to their high similarity in spectral characteristics; and 3) the co-occurring context, such as “sea,” distracts the model and thus degrades the performance. To address the above issues, in our proposed ProCAM, we first design a prototype reactivation (PRA) module that reactivates self-similar sea fog regions by pixel-to-prototype feature matching to improve the robustness and completeness of CAMs. Then, we develop a pixel-to-prototype contrastive (PPC) learning method to increase the distance between sea fog and background in the embedding space for learning more discriminative dense features. Finally, a self-augmented regularization (SAR) strategy is presented to decouple sea fog from its co-ocurring context, and thus avoid background interference. Extensive experiments on the WS-SFDD dataset demonstrate that our proposed method ProCAM achieves superior performance with an $F1$ score of 77.59% and a critical success index (CSI) of 63.39%. To the best of our knowledge, this is the first work to perform image-level weakly supervised sea fog detection in remote sensing images. The dataset and code are available at https://github.com/yixianghuang/ProCAM","tags":["Prototype learning","remote sensing image segmentation","sea fog detection","weakly supervised learning","Dataset"],"title":"Weakly Supervised Sea Fog Detection in Remote Sensing Images via Prototype Learning","type":"publication"},{"authors":["Haotian Yan","Sundingkai Su","Ming Wu","Mengqiu Xu","Yihao Zuo","Chuang Zhang","Bin Huang"],"categories":null,"content":"","date":1692576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692576000,"objectID":"02f83b321ec3b10c164ec997754ca2d4","permalink":"https://BUPT-PRIS-727.github.io/en/publication/seamae/","publishdate":"2023-08-21T00:00:00Z","relpermalink":"/en/publication/seamae/","section":"publication","summary":"Sea fog detection (SFD) presents a significant challenge in the field of intelligent Earth observation, particularly in analyzing meteorological satellite imagery. Akin to various vision tasks, ImageNet pre-training is commonly used for pre-training SFD. However, in the context of multi-spectral meteorological satellite imagery, the initial step of deep learning has received limited attention. Recently, pre-training with Very High-Resolution (VHR) satellite imagery has gained increased popularity in remote-sensing vision tasks, showing the potential to replace ImageNet pre-training. However, it is worth noting that the meteorological satellite imagery applied in SFD, despite being an application of computer vision in remote sensing, differs greatly from VHR satellite imagery. To address the limitation of pre-training for SFD, this paper introduces a novel deep-learning paradigm to the meteorological domain driven by Masked Image Modeling (MIM). Our research reveals two key insights: (1) Pre-training with meteorological satellite imagery yields superior SFD performance compared to pre-training with nature imagery and VHR satellite imagery. (2) Incorporating the architectural characteristics of SFD models into a vanilla masked autoencoder (MAE) can augment the effectiveness of meteorological pre-training. To facilitate this research, we curate a pre-training dataset comprising 514,655 temporal multi-spectral meteorological satellite images, covering the Bohai Sea and Yellow Sea regions, which have the most sea fog occurrence. The longitude ranges from 115.00E to 128.75E, and the latitude ranges from 27.60N to 41.35N. Moreover, we introduce SeaMAE, a novel MAE that utilizes a Vision Transformer as the encoder and a convolutional hierarchical decoder, to learn meteorological representations. SeaMAE is pre-trained on this dataset and fine-tuned for SFD, resulting in state-of-the-art performance. For instance, using the ViT-Base as the backbone, SeaMAE pre-training which achieves 64.18% surpasses from-scratch learning, natural imagery pre-training, and VRH satellite imagery pre-training by 5.53% , 2.49% , and 2.21% , respectively, in terms of Intersection over Union of SFD.","tags":["sea fog detection","pre-training","masked autoencoders","meteorological satellite imagery","Dataset"],"title":"SeaMAE: Masked Pre-Training with Meteorological Satellite Imagery for Sea Fog Detection","type":"publication"},{"authors":["Xun Zhu","Yutong Xiong","Ming Wu","Gaozhen Nie","Bin Zhang","Ziheng Yang"],"categories":null,"content":"","date":1676937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676937600,"objectID":"243f8ba8fff58662d5ffc06d4e1a9680","permalink":"https://BUPT-PRIS-727.github.io/en/publication/weather2k/","publishdate":"2023-02-21T00:00:00Z","relpermalink":"/en/publication/weather2k/","section":"publication","summary":"Weather forecasting is one of the cornerstones of meteorological work. In this paper, we present a new benchmark dataset named Weather2K, which aims to make up for the deficiencies of existing weather forecasting datasets in terms of real-time, reliability, and diversity, as well as the key bottleneck of data quality. To be specific, our Weather2K is featured from the following aspects: 1) Reliable and real-time data. The data is hourly collected from 2,130 ground weather stations covering an area of 6 million square kilometers. 2) Multivariate meteorological variables. 20 meteorological factors and 3 constants for position information are provided with a length of 40,896 time steps. 3) Applicable to diverse tasks. We conduct a set of baseline tests on time series forecasting and spatio-temporal forecasting. To the best of our knowledge, our Weather2K is the first attempt to tackle weather forecasting task by taking full advantage of the strengths of observation data from ground weather stations. Based on Weather2K, we further propose Meteorological Factors based Multi-Graph Convolution Network (MFMGCN), which can effectively construct the intrinsic correlation among geographic locations based on meteorological factors. Sufficient experiments show that MFMGCN improves both the forecasting performance and temporal robustness. We hope our Weather2K can significantly motivate researchers to develop efficient and accurate algorithms to advance the task of weather forecasting. The dataset can be available at https://github.com/bycnfz/weather2k/ .","tags":["Weather Forecasting","Dataset","Multi-Graph","Dataset"],"title":"Weather2K: A Multivariate Spatio-Temporal Benchmark Dataset for Meteorological Forecasting Based on Real-Time Observation Data from Ground Weather Stations","type":"publication"},{"authors":["Rui Min","Ming Wu","Mengqiu Xu","Xun Zhu"],"categories":null,"content":"","date":1674086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674086400,"objectID":"9308710fe9c3b6c4714df4f3d72f312c","permalink":"https://BUPT-PRIS-727.github.io/en/publication/attention-based-long-short-term-memory-network-for-coastal-visibility-forecast/","publishdate":"2023-01-19T00:00:00Z","relpermalink":"/en/publication/attention-based-long-short-term-memory-network-for-coastal-visibility-forecast/","section":"publication","summary":"Visibility prediction in coastal areas has always been an important issue affecting the safety of residents and the efficiency of urban transportation. The visibility prediction methods currently used by meteorological centers are mainly based on the statistical forecast with relatively low prediction accuracy and high computational complexity. These methods cannot work well with large amounts of data. However, with the rapid development of deep learning technology, the use of deep learning has become a primary trend. In this paper, we propose our visibility prediction model based on (Long Short-Term Memory) LSTM network and self-attention mechanism. The model takes Medium-range Forecasts Data from European Centre for Mediumrange Weather Forecasting (ECMWF) which we use EC data to refer it for simplicity and observatory visibility data as input to predict and uses the LSTM network as the backbone to extract time series information. We also use self-attention mechanism to process the input data before the data is input to the model to let the model better focus on the valuable information for prediction. Compared with the predicted visibility in EC data, our proposed method improved the 3-hour prediction accuracy by 20%, 1.5 times, and 8 times for high-range, medium-range, and low-range visibility, respectively. We also find the data imbalance will greatly affect the prediction accuracy for low-visibility data and use the weighted-loss and mix-up data augmentation strategy model in our model training. We improved the accuracy of low-visibility data by 1.2 times while the prediction results of high-visibility and medium-visibility data remained almost the same. In addition, we conduct several experiments to verify the effectiveness of our model design and the rationality of data augmentation.","tags":["Coastal visibility prediction","Deep learning","Long short-term memory","Self-attention","Data imbalance"],"title":"Attention based Long Short-Term Memory Network for Coastal Visibility Forecast","type":"publication"},{"authors":["Xun Zhu","Mengqiu Xu","Ming Wu","Chuang Zhang","Bin Zhang"],"categories":null,"content":"","date":1673827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673827200,"objectID":"08736f10a0585a11d149c0e521cca868","permalink":"https://BUPT-PRIS-727.github.io/en/publication/annotating-only-at-definite-pixels-a-novel-weakly-supervised-semantic-segmentation-method-for-sea-fog-recognition/","publishdate":"2023-01-16T00:00:00Z","relpermalink":"/en/publication/annotating-only-at-definite-pixels-a-novel-weakly-supervised-semantic-segmentation-method-for-sea-fog-recognition/","section":"publication","summary":"Sea fog recognition is a challenging and significant semantic segmentation task in remote sensing images. The fully supervised learning method relies on the pixel-level label, which is labor-intensive and time-consuming. Moreover, it is impossible to accurately annotate all pixels of the sea fog region due to the limited ability of the human eye to distinguish between low clouds and sea fog. In this paper, we propose a novel approach of point-based annotation for weakly supervised semantic segmentation with the auxiliary information of International Comprehensive Ocean-Atmosphere Data Set (ICOADS) visibility data. It only needs several definite points for both foreground and background, which significantly reduces the annotation cost of manpower. We conduct extensive experiments on Himawari-8 satellite remote sensing images to demonstrate the effectiveness of our annotation method. The mean intersection over union (mIoU) and overall recognition accuracy of our annotation method reach 82.72% and 95.18 %, respectively. Compared with the fully supervised learning method, the accuracy and the recognition rate of sea fog area are improved with a maximum increase of 7.69% and 9.69 %, respectively.","tags":["sea fog recognition","weakly supervised learning","point annotation","semantic segmentation","remote sensing image"],"title":"Annotating Only at Definite Pixels- A Novel Weakly Supervised Semantic Segmentation Method for Sea Fog Recognition","type":"publication"},{"authors":["Sibo Wu","Mengqiu Xu","Ming Wu","Chuang Zhang","Hua Shen"],"categories":null,"content":"","date":1673827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673827200,"objectID":"60ab76e950af710159f6b4feb8a14d03","permalink":"https://BUPT-PRIS-727.github.io/en/publication/identify-guess-and-reconstruct-three-principles-for-cloud-removal-task/","publishdate":"2023-01-16T00:00:00Z","relpermalink":"/en/publication/identify-guess-and-reconstruct-three-principles-for-cloud-removal-task/","section":"publication","summary":"Remote sensing images serve a significant role in earth observation to tackle climate change and post-disaster reconstruction concerns. However, optical images are obscured by clouds or haze, preventing precise earth observation; hence, cloud removal has been a hot topic among concerned scholars. The objective of this article is to make cloud removal more efficient and explicable by proposing three principles: identifying clouds, guessing objects beneath the clouds, and reconstructing the cloudy area. In addition, a modified dual contrastive learning Generative Adversarial Network is proposed based on these three principles by adding cloud detection and weight sharing strategy to obtain cloud semantics. In particular, we align two datasets by forming a quaternary sample pair that includes not only optical pictures and SAR images, but also region information for a more precise reconstruction. Our experiment results on the integrated dataset reveal the superiority of proposed method over previous cloud removal methods and the effectiveness of added modules through ablation experiments, with PSNR and SSIM values of 26.2 and 0.728, respectively.","tags":["Cloud Removal","Dual Contrastive Learning GAN","Remote Sensing","Deep Learning"],"title":"Identify, Guess and Reconstruct- Three Principles for Cloud Removal Task","type":"publication"},{"authors":["Mengqiu Xu","Ming Wu","Kaixin Chen","Chuang Zhang","Jun Guo"],"categories":null,"content":"","date":1662163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662163200,"objectID":"003f696e8c979848d7776392fc541d77","permalink":"https://BUPT-PRIS-727.github.io/en/publication/the-eyes-of-the-gods/","publishdate":"2022-09-03T00:00:00Z","relpermalink":"/en/publication/the-eyes-of-the-gods/","section":"publication","summary":"With the rapid development of the remote sensing monitoring and computer vision technology, the deep learning method has made a great progress to achieve applications such as earth observation, climate change and even space exploration. However, the model trained on existing data cannot be directly used to handle the new remote sensing data, and labeling the new data is also time-consuming and labor-intensive. Unsupervised Domain Adaptation (UDA) is one of the solutions to the aforementioned problems of labeled data defined as the source domain and unlabeled data as the target domain, i.e., its essential purpose is to obtain a well-trained model and tackle the problem of data distribution discrepancy defined as the domain shift between the source and target domain. There are a lot of reviews that have elaborated on UDA methods based on natural data, but few of these studies take into consideration thorough remote sensing applications and contributions. Thus, in this paper, in order to explore the further progress and development of UDA methods in remote sensing, based on the analysis of the causes of domain shift, a comprehensive review is provided with a fine-grained taxonomy of UDA methods applied for remote sensing data, which includes Generative training, Adversarial training, Self-training and Hybrid training methods, to better assist scholars in understanding remote sensing data and further advance the development of methods. Moreover, remote sensing applications are introduced by a thorough dataset analysis. Meanwhile, we sort out definitions and methodology introductions of partial, open-set and multi-domain UDA, which are more pertinent to real-world remote sensing applications. We can draw the conclusion that UDA methods in the field of remote sensing data are carried out later than those applied in natural images, and due to the domain gap caused by appearance differences, most of methods focus on how to use generative training (GT) methods to improve the model’s performance. Finally, we describe the potential deficiencies and further in-depth insights of UDA in the field of remote sensing.","tags":["unsupervised domain adaptation","remote sensing data","a survey","deep learning"],"title":"The Eyes of the Gods: A Survey of Unsupervised Domain Adaptation Methods Based on Remote Sensing Data","type":"publication"},{"authors":["Bin Huang","Luming Xiao","Wen Feng","Mengqiu Xu","Ming Wu","Xiang Fang"],"categories":null,"content":"","date":1660262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660262400,"objectID":"5a82eeea8c944691a78473fee2ac493b","permalink":"https://BUPT-PRIS-727.github.io/en/publication/domain-adaptation-on-multiple-cloud-recognition-from-different-types-of-meteorological-satellite/","publishdate":"2022-08-12T00:00:00Z","relpermalink":"/en/publication/domain-adaptation-on-multiple-cloud-recognition-from-different-types-of-meteorological-satellite/","section":"publication","summary":"Meteorological satellites have become an indispensable meteorological tool for earth observation, as aiding in areas such as cloud detection, which has important guiding significance for maritime activities. However, it is time-consuming and labor-intensive to obtain fine-grained annotations provided by artificial experience or mature satellite cloud products for multi-spectral maritime cloud imageries, especially when new satellites are launched. Moreover, due to the data discrepancy caused by different detection bands, existing models have inadequate generalization performance compared to new satellites, and some cannot be directly migrated. In this paper, to reduce the data distribution’s discrepancy, an approach is presented based on unsupervised domain adaption method for marine cloud detection task based on Himawari-8 satellite data as a source domain and Fengyun-4 satellite data as a target domain. The goal of the proposed method is to leverage the representation power of adversarial learning to extract domain-invariant features, consisting of a segmentation model, a feature extract model for target domain, and a domain discriminator. In addition, aiming to remedy the discrepancy of detection bands, a band mapping module is designed to implement consistency between different bands. The result of the experiments demonstrated the effectiveness of the proposed method with a 7% improvement compared with the comparative experiment. We also designed a series of statistical experiments on different satellite data to further study cloudy perception representation, including data visualization experiment and cloud type statistics.","tags":["marine cloud classification","unsupervised domain adaptation","deep learning","transfer learning","semantic segmentation"],"title":"Domain Adaptation on Multiple Cloud Recognition From Different Types of Meteorological Satellite","type":"publication"},{"authors":["Mengqiu Xu","Ming Wu","Jun Guo","Chuang Zhang","Yubo Wang","Zhangyu Ma"],"categories":null,"content":"","date":1648771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648771200,"objectID":"30540b983571befd4b7a883dd51642dc","permalink":"https://BUPT-PRIS-727.github.io/en/publication/sea-fog-detection-based-on-unsupervised-domain-adaptation/","publishdate":"2022-04-01T00:00:00Z","relpermalink":"/en/publication/sea-fog-detection-based-on-unsupervised-domain-adaptation/","section":"publication","summary":"Sea fog detection with remote sensing images is a challenging task. Driven by the different image characteristics between fog and other types of clouds, such as textures and colors, it can be achieved by using image processing methods. Currently, most of the available methods are data-driven and relying on manual annotations. However, because few meteorological observations and buoys over the sea can be realized, obtaining visibility information to help the annotations is difficult. Considering the feasibility of obtaining abundant visible information over the land and the similarity between land fog and sea fog, we propose an unsupervised domain adaptation method to bridge the abundant labeled land fog data and the unlabeled sea fog data to realize the sea fog detection. We used a seeded region growing module to obtain pixel-level masks from rough-labels generated by the unsupervised domain adaptation model. Experimental results demonstrate that our proposed method achieves an accuracy of sea fog recognition up to 99.17%, which is nearly 3% higher than those vanilla methods.","tags":["Deep learning","Sea fog detection","Seeded region growing","Transfer learning","Unsupervised domain","adaptation"],"title":"Sea fog detection based on unsupervised domain adaptation","type":"publication"},{"authors":["Bin Huang","Ming Wu","Shuyue Sun","Wei Zhao","Zhanbei Cui","Cheng Lv"],"categories":null,"content":"","date":1640908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640908800,"objectID":"bd03b0fa41f7ceb05b4703cb8ff7f914","permalink":"https://BUPT-PRIS-727.github.io/en/publication/sea-fog-monitoring-method-based-on-deep-learning-satellite-multi-channel-image-fusion/","publishdate":"2021-12-31T00:00:00Z","relpermalink":"/en/publication/sea-fog-monitoring-method-based-on-deep-learning-satellite-multi-channel-image-fusion/","section":"publication","summary":"Sea fog, whether on the sea or the coast, has adverse effects on transportation, marine fishing, marine development projects, and military activities due to its poor visibility. Therefore, realtime monitoring and forecasting of sea fog are essential. This paper proposes a multichannel image fusion segmentation algorithm for stationary meteorological satellites based on deep learning. The DLinkNet deep neural network semantic segmentation algorithm model is used to study the 16channel Himawari8 satellite data with a spatial resolution of 0.5 km in the Yellow Sea and the Bohai Sea. Using mIOU (mean Intersection Over Union) and observation value test as evaluation indicators, the mIOU on the test set is 0.9436, and comparing the results of satellite test data with the results of marine observation data. It was concluded that the accuracy rate of fog area (detect fog and real fog / detect fog) is 66.5%, the recognition rate of fog area (detect fog and real fog / (real fog-cloud coverage)) is 51.9%, and the detection accuracy rate (detection correct samples / total samples) is 93.2%. In conclusion, the method proposed in this paper can provide a reliable reference for sea fog monitoring.","tags":["sea fog detection","multi-channel image fusion","D-LinkNet","Himawari-8"],"title":"Sea Fog Monitoring Method Based on Deep Learning Satellite Multi-channel Image Fusion","type":"publication"},{"authors":["Bin Huang","Ming Wu","Mengqiu Xu","Yanzhen Qian","Fengqin Zheng","Luming Xiao","Shuyue Sun","Longsheng Liu"],"categories":null,"content":"","date":1639094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639094400,"objectID":"82c8b6050a311dac448568d7d05fa523","permalink":"https://BUPT-PRIS-727.github.io/en/project/%E5%9F%BA%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9F%9F%E9%80%82%E5%BA%94%E7%9A%84%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E7%9A%84%E5%A4%9A%E4%BA%91%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/","publishdate":"2021-12-10T00:00:00Z","relpermalink":"/en/project/%E5%9F%BA%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9F%9F%E9%80%82%E5%BA%94%E7%9A%84%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E7%9A%84%E5%A4%9A%E4%BA%91%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/","section":"project","summary":"","tags":null,"title":"基于无监督域适应的不同类型气象卫星的多云识别系统","type":"project"},{"authors":["Ming Wu","Yixiang Huang","Chuang Zhang","Kaiyan Chen","Sundingkai Su"],"categories":null,"content":"","date":1629763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629763200,"objectID":"2734d7b85166fecedf6e3bb9c26dfbdd","permalink":"https://BUPT-PRIS-727.github.io/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E6%9C%89%E7%9B%91%E7%9D%A3%E5%81%87%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F%E5%90%88%E6%88%90%E6%96%B9%E6%B3%95/","publishdate":"2021-08-24T00:00:00Z","relpermalink":"/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E6%9C%89%E7%9B%91%E7%9D%A3%E5%81%87%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F%E5%90%88%E6%88%90%E6%96%B9%E6%B3%95/","section":"project","summary":"","tags":null,"title":"一种基于机器学习算法的有监督假彩色图像合成方法","type":"project"},{"authors":["Yixiang Huang","Ming Wu","Jun Guo","Chuang Zhang","Mengqiu Xu"],"categories":null,"content":"","date":1627257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627257600,"objectID":"cde9f72c94d1dc795773ff14829082ae","permalink":"https://BUPT-PRIS-727.github.io/en/publication/a-correlation-context-driven-method-for-sea-fog-detection-in-meteorological-satellite-imagery/","publishdate":"2021-07-26T00:00:00Z","relpermalink":"/en/publication/a-correlation-context-driven-method-for-sea-fog-detection-in-meteorological-satellite-imagery/","section":"publication","summary":"Sea fog detection is a challenging and essential issue in satellite remote sensing. Although conventional threshold methods and deep learning methods can achieve pixel-level classification, it is difficult to distinguish ambiguous boundaries and thin structures from the background. Considering the correlations between neighbor pixels and the affinities between superpixels, a correlation context-driven method for sea fog detection is proposed in this letter, which mainly consists of a two-stage superpixel-based fully convolutional network (SFCNet), named SFCNet. A fully connected Conditional Random Field (CRF) is utilized to model the dependencies between pixels. To alleviate the problem of high cloud occlusion, an attentive Generative Adversarial Network (GAN) is implemented for image enhancement by exploiting contextual information. Experimental results demonstrate that our proposed method achieves 91.65% mIoU and obtains more refined segmentation results, performing well in detecting fogs in small, broken bits and weak contrast thin structures, as well as detects more obscured parts.","tags":["Deep learning","satellite imagery","sea fog detection","superpixel"],"title":"A Correlation Context-Driven Method for Sea Fog Detection in Meteorological Satellite Imagery","type":"publication"},{"authors":["Ming Wu","Bin Huang","Zhanbei Cui","Chuang Zhang","Chuanhai Qian","Wei Zhao"],"categories":null,"content":"","date":1611878400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611878400,"objectID":"933ac3c557c2bafcedc83e205a78b377","permalink":"https://BUPT-PRIS-727.github.io/en/project/%E5%9F%BA%E4%BA%8E%E9%9D%99%E6%AD%A2%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E5%BD%B1%E5%83%8F%E5%BA%8F%E5%88%97%E7%9A%84%E4%BA%91%E9%9B%BE%E8%87%AA%E5%8A%A8%E5%88%A4%E8%AF%86%E6%96%B9%E6%B3%95%E5%8F%8A%E7%B3%BB%E7%BB%9F/","publishdate":"2021-01-29T00:00:00Z","relpermalink":"/en/project/%E5%9F%BA%E4%BA%8E%E9%9D%99%E6%AD%A2%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E5%BD%B1%E5%83%8F%E5%BA%8F%E5%88%97%E7%9A%84%E4%BA%91%E9%9B%BE%E8%87%AA%E5%8A%A8%E5%88%A4%E8%AF%86%E6%96%B9%E6%B3%95%E5%8F%8A%E7%B3%BB%E7%BB%9F/","section":"project","summary":"","tags":null,"title":"基于静止气象卫星影像序列的云雾自动判识方法及系统","type":"project"},{"authors":["Bin Huang","Chuanhai Qian","Guanting Li","Ming Wu","Wei Zhao","Chuang Zhang"],"categories":null,"content":"","date":1609804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609804800,"objectID":"f07a7e4bf54e61483436f43904ff40e2","permalink":"https://BUPT-PRIS-727.github.io/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E5%9B%BE%E5%83%8F%E5%92%8C%E6%B7%B1%E5%BA%A6%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E9%9B%BE%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95/","publishdate":"2021-01-05T00:00:00Z","relpermalink":"/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B0%94%E8%B1%A1%E5%8D%AB%E6%98%9F%E5%9B%BE%E5%83%8F%E5%92%8C%E6%B7%B1%E5%BA%A6%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E9%9B%BE%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95/","section":"project","summary":"","tags":null,"title":"一种基于气象卫星图像和深度迁移学习的海雾识别方法","type":"project"},{"authors":["Chuang Zhang","Ming Wu","Nan Li"],"categories":null,"content":"","date":1567728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567728000,"objectID":"fe53873abc9a119fa2e3b3020eb017a5","permalink":"https://BUPT-PRIS-727.github.io/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8D%AB%E6%98%9F%E5%9B%BE%E5%83%8F%E7%9A%84%E7%A9%BA%E6%B0%94%E6%B1%A1%E6%9F%93%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95/","publishdate":"2019-09-06T00:00:00Z","relpermalink":"/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8D%AB%E6%98%9F%E5%9B%BE%E5%83%8F%E7%9A%84%E7%A9%BA%E6%B0%94%E6%B1%A1%E6%9F%93%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95/","section":"project","summary":"","tags":null,"title":"一种基于深度学习和卫星遥感技术的海雾检测方法","type":"project"},{"authors":["Ming Wu","Chuang Zhang","Jinyu Chen"],"categories":null,"content":"","date":1562284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562284800,"objectID":"ba47e86f7b4a0c1b6067a5322a70a4e9","permalink":"https://BUPT-PRIS-727.github.io/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%8D%AB%E6%98%9F%E9%81%A5%E6%84%9F%E6%8A%80%E6%9C%AF%E7%9A%84%E6%B5%B7%E9%9B%BE%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95/","publishdate":"2019-07-05T00:00:00Z","relpermalink":"/en/project/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%8D%AB%E6%98%9F%E9%81%A5%E6%84%9F%E6%8A%80%E6%9C%AF%E7%9A%84%E6%B5%B7%E9%9B%BE%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95/","section":"project","summary":"","tags":null,"title":"一种基于卫星图像的空气污染估计方法","type":"project"}]